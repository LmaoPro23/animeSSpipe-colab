config_dir: 'hcp_configs'

data:
  dataset1:
    _target_: hcpdiff.data.TextImagePairDataset
    _partial_: True # Not directly instantiate the object here. There are other parameters to be added in the runtime.
    batch_size: 8
    cache_latents: True
    att_mask_encode: False
    loss_weight: 1.0

    source:
      data_source_1:
        img_root: 'imgs/'
        repeat: 1
        prompt_template: '${config_dir}/caption.txt'
        caption_file:
          _target_: hcpdiff.data.TXTCaptionLoader
          path: 'imgs/'

        att_mask: null
        bg_color: [ 255, 255, 255 ] # RGB; for ARGB -> RGB

        word_names: {}

        image_transforms:
          _target_: torchvision.transforms.Compose # "_target_" for hydra.utils.instantiate
          transforms:
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [ 0.5 ]
              std: [ 0.5 ]
        tag_transforms:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: hcpdiff.utils.caption_tools.TagDropout
              p: 0
          #   - _target_: hcpdiff.utils.caption_tools.TagShuffle
          #   - _target_: hcpdiff.utils.caption_tools.TemplateFill
          #     word_names: ${....word_names}

    bucket:
      # _target_: hcpdiff.data.bucket.RatioBucket.from_files # the buckets are automatically selected but this would require recaching latents when dataset changes
      _target_: hcpdiff.data.bucket.RatioBucket.from_ratios # aspect ratio bucket with fixed ratios
      target_area: ${hcp.eval:"512*512"}
      num_bucket: 10
