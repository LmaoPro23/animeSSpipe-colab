# base_state*base_model_alpha + (lora_state[i]*lora_scale[i]*lora_alpha[i]) + (part_state[k]*part_alpha[k])
exp_dir: 'exps/2023-07-26-01-05-35'  # experiment directory
model_steps: 1000  # steps of selected model
emb_dir: '${exp_dir}/ckpts/'

pretrained_model: 'deepghs/animefull-latest'
prompt: ''
neg_prompt: 'lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry'
N_repeats: 1
clip_skip: 1
clip_final_norm: True
bs: 1
num: 1
seed: null
dtype: 'fp16'

condition: null

ex_input: {}

# Syntactic sugar for interface
save:
  out_dir: 'output/'
  save_cfg: True
  image_type: png
  quality: 95
#  image_type: webp
#  quality: 75

offload: null

#vae_optimize: null
vae_optimize:
  tiling: False
  slicing: False

interface:
  - _target_: hcpdiff.vis.DiskInterface
    show_steps: 0
    save_root: ${save.out_dir}
    save_cfg: ${save.save_cfg}
    image_type: ${save.image_type}
    quality: ${save.quality}

infer_args:
  width: 512
  height: 640
  guidance_scale: 7.5
  num_inference_steps: 25

new_components:
  scheduler:
    _target_: diffusers.EulerAncestralDiscreteScheduler # change Sampler
    beta_start: 0.00085
    beta_end: 0.012
    beta_schedule: 'scaled_linear'

merge:
  plugin_cfg: loha.yaml
  alpha: 1

  group_unet:
    type: 'unet'
    base_model_alpha: 1.0
    plugin:
      loha:
        path: '${.....exp_dir}/ckpts/unet-${.....model_steps}.safetensors'
        alpha: ${....alpha}
        layers: 'all'

  group_TE:
    type: 'TE'
    base_model_alpha: 1.0
    plugin:
      loha:
        path: '${.....exp_dir}/ckpts/text_encoder-${.....model_steps}.safetensors'
        alpha: ${....alpha}
        layers: 'all'
